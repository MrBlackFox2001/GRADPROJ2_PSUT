{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import boto3\n",
    "import tarfile\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def download_model_from_s3(s3_uri, local_path):\n",
    "    bucket, key = s3_uri.lstrip('s3://').split('/', 1)\n",
    "    s3.download_file(bucket, key, local_path)\n",
    "\n",
    "def predict_ecg_class(event, context):\n",
    "    # Extract the image file from the multipart/form-data\n",
    "    image_file = event['files']['img'][0]\n",
    "\n",
    "    # Save the image to a temporary file\n",
    "    temp_image_path = '/tmp/uploaded_image.png'\n",
    "    with open(temp_image_path, 'wb') as f:\n",
    "        f.write(image_file['content'])\n",
    "\n",
    "    # Run plotdigitizer and preprocess the custom DataFrame\n",
    "    command = f'plotdigitizer \"{temp_image_path}\" -p 0,0 -p 2,0 -p 0,1 -l 2,29 -l 4,5 -l 22,5'\n",
    "    output = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    temp_csv_path = os.path.splitext(temp_image_path)[0] + \".traj.csv\"\n",
    "    df = pd.read_csv(temp_csv_path, sep=' ', header=None)\n",
    "    robust_scaler = RobustScaler()\n",
    "    df = pd.DataFrame(robust_scaler.fit_transform(df), columns=df.columns)\n",
    "    df = df.iloc[:, 1:2]\n",
    "    df = df.head(10).T.reset_index(drop=True)\n",
    "    df.columns = ['0_pre-RR', '0_pPeak', '0_rPeak', '0_sPeak', '0_qt_interval', '1_pre-RR', '1_qPeak', '1_qt_interval', '1_qrs_morph0', '1_qrs_morph1']\n",
    "    \n",
    "    # Assuming your model expects input with shape (batch_size, num_features)\n",
    "    custom_data = df.values.reshape((1, -1))\n",
    "\n",
    "    # Load the pre-trained model from S3\n",
    "    s3_model_uri = 's3://psutgrad/ecg_classifier.tar.gz'\n",
    "    model_local_path = '/tmp/ecg_classifier.tar.gz'\n",
    "    download_model_from_s3(s3_model_uri, model_local_path)\n",
    "    \n",
    "    # Extract the model from the tar.gz file\n",
    "    with tarfile.open(model_local_path, 'r:gz') as tar:\n",
    "        tar.extractall('/tmp/')\n",
    "\n",
    "    # Load the model\n",
    "    model_path = '/tmp/ecg_classifier.h5'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(custom_data)\n",
    "\n",
    "    # Display predictions or use them as needed\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    class_mapping = {\n",
    "        0: 'Normal Beat',\n",
    "        1: 'Ventricular Beat',\n",
    "        2: 'Supraventricular Beat',\n",
    "        3: 'Fusion Beat'\n",
    "    }\n",
    "\n",
    "    predicted_class_label = class_mapping.get(predicted_class_index, 'Unknown')\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps({'predicted_class_label': predicted_class_label})\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
